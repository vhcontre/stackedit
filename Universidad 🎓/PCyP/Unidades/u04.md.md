# **📌 Unidad 4: Diseño de Patrones para Programación Concurrente**

## 🔹 **Definición e Introducción a Patrones de Diseño**

En la programación concurrente, los **patrones de diseño** son soluciones reutilizables que nos ayudan a resolver problemas comunes que surgen cuando trabajamos con múltiples hilos o tareas concurrentes. Estos patrones nos permiten estructurar nuestro código de forma más eficiente, reducir el riesgo de errores y mejorar el rendimiento.

Los patrones de diseño proporcionan una guía sobre cómo organizar la interacción entre los diferentes componentes de un sistema concurrente, haciendo que el código sea más claro y fácil de mantener.

<br />

## 🔹 **💡 Patrón "Pipeline"**

El **Patrón Pipeline** es utilizado cuando los datos necesitan ser procesados en una serie de etapas. Cada etapa en el pipeline procesa una parte de los datos y pasa el resultado a la siguiente etapa.

Este patrón es especialmente útil cuando tenemos un flujo de trabajo que puede dividirse en varios pasos, y cada paso puede ejecutarse en paralelo, independientemente de los demás.

**Ejemplo en C#:**

```csharp
using System;
using System.Threading.Tasks;

class Program
{
    static void Main()
    {
        // Paso 1: Generar datos
        var data = new int[] { 1, 2, 3, 4, 5 };

        // Paso 2: Procesar datos en paralelo (Pipeline)
        var processedData = Task.WhenAll(data.Select(d => Task.Run(() => ProcessData(d))));

        // Esperamos que todos los pasos de procesamiento terminen
        processedData.Wait();
        Console.WriteLine("Procesamiento completado.");
    }

    static int ProcessData(int data)
    {
        // Simulación de procesamiento
        Console.WriteLine($"Procesando {data}...");
        return data * 2;
    }
}

```

Este ejemplo demuestra cómo se pueden procesar datos en paralelo usando el patrón Pipeline, donde cada dato se procesa de manera independiente y luego se pasa a la siguiente etapa de procesamiento.

----------

### ¿Qué es el patrón Pipeline?

Es un patrón de diseño que divide el procesamiento de datos en una serie de etapas independientes, donde la salida de una etapa puede ser la entrada de la siguiente. Aunque tradicionalmente estas etapas están encadenadas, aquí usamos tareas paralelas para procesar cada elemento individualmente, lo cual es una **forma concurrente del pipeline**.

----------

### Paso a paso del código

```csharp
var data = new int[] { 1, 2, 3, 4, 5 };

```

🔹 **Paso 1: Fuente de datos**

-   Se declara un arreglo de enteros que actúa como datos de entrada.
    
-   Esto simula, por ejemplo, elementos que deben ser procesados uno a uno.
    

----------

```csharp
var processedData = Task.WhenAll(
    data.Select(d => Task.Run(() => ProcessData(d)))
);

```

🔹 **Paso 2: Lanzar tareas paralelas**

-   `data.Select(...)` transforma cada número en una tarea asíncrona con `Task.Run`.
    
-   `ProcessData(d)` simula el procesamiento de cada elemento.
    
-   `Task.WhenAll(...)` espera que **todas las tareas se completen** y devuelve un arreglo de resultados.
    
-   Aquí estamos aplicando un pipeline _en paralelo_: cada tarea representa una etapa independiente del procesamiento.
    

----------

```csharp
processedData.Wait();

```

🔹 **Paso 3: Esperar el resultado**

-   `Wait()` bloquea el hilo principal hasta que todas las tareas finalicen.
    

----------

```csharp
foreach (var result in processedData.Result)
{
    Console.WriteLine($"Resultado: {result}");
}

```

🔹 **Paso 4: Mostrar los resultados**

-   Se recorren los resultados devueltos por las tareas y se imprime cada uno.
    
-   La propiedad `.Result` accede a los valores retornados por cada tarea.
    

----------

```csharp
static int ProcessData(int data)
{
    Console.WriteLine($"Procesando {data}...");
    return data * 2;
}

```

🔹 **Paso 5: Función de procesamiento**

-   Simula una operación sobre los datos (multiplicación por 2).
    
-   Imprime por consola qué dato está siendo procesado.
    

----------

### ¿Qué logramos con esto?

-   **Paralelismo**: Cada elemento del array se procesa en su propia tarea.
    
-   **Escalabilidad**: Aprovecha varios núcleos del CPU si están disponibles.
    
-   **Simplicidad**: Aunque no hay múltiples etapas, cada tarea actúa como una "etapa" autónoma del pipeline.
    

----------

### ¿Podría mejorarse?

Un pipeline más realista podrías tener:

-   Múltiples etapas encadenadas (por ejemplo, map → filter → reduce).
    
-   Uso de `TPL Dataflow` o `Channels` en lugar de solo `Task.WhenAll`.
    

Perfecto. Vamos a llevar el ejemplo anterior a un **pipeline encadenado más realista**, simulando **múltiples etapas de procesamiento** (como las que podrías encontrar en procesamiento de datos, imágenes, o flujo de eventos). Luego, más adelante, podemos profundizar en el patrón **Dataflow**.

----------

### 🏗️ Pipeline Realista con Tareas Encadenadas en C#

Cada dato pasará por **tres etapas secuenciales**, pero cada dato se procesa en paralelo con respecto a los demás.

```csharp
using System;
using System.Linq;
using System.Threading.Tasks;

class Program
{
    static async Task Main()
    {
        var datos = new int[] { 1, 2, 3, 4, 5 };

        // Ejecutar el pipeline para cada dato en paralelo
        var resultados = await Task.WhenAll(
            datos.Select(async dato =>
            {
                var etapa1 = await Etapa1Async(dato);
                Console.WriteLine($"Dato {dato} → Etapa 1: {etapa1}");

                var etapa2 = await Etapa2Async(etapa1);
                Console.WriteLine($"Dato {dato} → Etapa 2: {etapa2}");

                var etapa3 = await Etapa3Async(etapa2);
                Console.WriteLine($"Dato {dato} → Etapa 3 (resultado final): {etapa3}");

                return etapa3;
            })
        );

        Console.WriteLine("\n=== Resultados finales ===");
        foreach (var resultado in resultados)
        {
            Console.WriteLine($"Resultado: {resultado}");
        }
    }

    static Task<int> Etapa1Async(int valor)
    {
        // Suma 1 al valor
        return Task.FromResult(valor + 1);
    }

    static Task<int> Etapa2Async(int valor)
    {
        // Multiplica por 2
        return Task.FromResult(valor * 2);
    }

    static Task<int> Etapa3Async(int valor)
    {
        // Resta 3
        return Task.FromResult(valor - 3);
    }
}


```

----------

### Detalle de la operación concurrente

1.  **Paralelismo entre datos**: Cada dato se procesa en su propia cadena de tareas.
    
2.  **Secuencia dentro del pipeline**: Las etapas se ejecutan en orden para cada dato (Etapa 1 → Etapa 2 → Etapa 3).
    
3.  **Task.WhenAll(...)** espera que todos los flujos de datos finalicen.
    

----------

### Ejemplo visual del flujo:

```
2 --> Etapa1 (2+1 = 3)
   --> Etapa2 (3*2 = 6)
   --> Etapa3 (6-3 = 3)

```

Esto se hace para todos los datos al mismo tiempo, pero cada uno sigue esa misma cadena.

<br />

## 🔹 **🔄 Patrón "Dataflow"**

El **Patrón Dataflow** es similar al patrón Pipeline, pero más general. Aquí, los datos fluyen a través de varios nodos (procesos o tareas) y son procesados de forma independiente. Este patrón es útil cuando necesitamos que varias tareas puedan consumir los mismos datos, pero a la vez, puedan ejecutarse de forma independiente.

**Ejemplo en C#:**

```csharp
using System;
using System.Threading.Tasks;

class Program
{
    static void Main()
    {
        // Crear una colección de datos
        var data = new int[] { 1, 2, 3, 4, 5 };

        // Tareas paralelas para procesar los datos con Dataflow
        var tasks = data.Select(d => Task.Run(() => ProcessData(d)));

        // Esperar que todas las tareas se completen
        Task.WhenAll(tasks).Wait();

        Console.WriteLine("Procesamiento completo.");
    }

    static void ProcessData(int data)
    {
        Console.WriteLine($"Procesando {data}...");
    }
}

```

En este ejemplo, cada elemento de la colección es procesado de manera independiente utilizando el patrón Dataflow. Las tareas se ejecutan en paralelo y permiten un flujo eficiente de datos.

Explicación paso a paso de este código que simula un **patrón Dataflow**, aunque no usa directamente la librería `System.Threading.Tasks.Dataflow`, pero sí representa su esencia: **procesamiento paralelo de datos en etapas independientes**.

---

###  Paso a paso del código:

#### 🔹 1. **Definición de los datos**
```csharp
var data = new int[] { 1, 2, 3, 4, 5 };
```
Se crea una colección de datos (un arreglo de enteros). Estos son los “elementos” que pasarán por el flujo de procesamiento.

---

#### 🔹 2. **Inicio del procesamiento paralelo**
```csharp
var tasks = data.Select(d => Task.Run(() => ProcessData(d)));
```
Cada elemento del arreglo se procesa en paralelo usando `Task.Run()`. Esto lanza una nueva tarea por cada número, que se ejecutará de forma asíncrona.  
📌 Aquí cada "nodo" del flujo procesa un dato, como en un bloque de acción en Dataflow.

---

#### 🔹 3. **Esperar la finalización de todas las tareas**
```csharp
Task.WhenAll(tasks).Wait();
```
Se espera a que **todas las tareas paralelas finalicen** antes de continuar. Este paso sincroniza el flujo, asegurando que el programa no termine antes de tiempo.

---

#### 🔹 4. **Salida final**
```csharp
Console.WriteLine("Procesamiento completo.");
```
Una vez que todo el procesamiento ha terminado, se imprime un mensaje de confirmación.

---

#### 🔹 5. **Método de procesamiento**
```csharp
static void ProcessData(int data)
{
    Console.WriteLine($"Procesando {data}...");
}
```
Cada tarea llama a este método, que simplemente **simula un procesamiento** mostrando qué número está siendo tratado.

---

### ¿Es realmente Dataflow?

Aunque este ejemplo no usa bloques explícitos como `TransformBlock` o `BufferBlock`, **simula el patrón Dataflow** en su forma más simple:

- Entrada → procesamiento independiente → sincronización final.
- Usa **paralelismo con tareas** para imitar el flujo de datos asincrónico y segmentado del patrón.

>Se muestra **versión real del patrón Dataflow** usando la biblioteca `System.Threading.Tasks.Dataflow`, que forma parte del espacio de nombres `System.Threading.Tasks.Dataflow`. Este patrón permite **encadenar bloques de procesamiento asincrónicos y paralelos**, ideal para flujos de trabajo tipo “pipeline”.

---

### Ejemplo usando `Dataflow`

```csharp
using System;
using System.Threading.Tasks;
using System.Threading.Tasks.Dataflow;

class Program
{
    static async Task Main()
    {
        // Paso 1: Crear el bloque de entrada (TransformBlock)
        var transformBlock = new TransformBlock<int, int>(n =>
        {
            Console.WriteLine($"Procesando {n}...");
            return n * 2; // Simulamos procesamiento
        });

        // Paso 2: Crear el bloque de salida (ActionBlock)
        var actionBlock = new ActionBlock<int>(result =>
        {
            Console.WriteLine($"Resultado: {result}");
        });

        // Paso 3: Encadenar bloques (link)
        transformBlock.LinkTo(actionBlock, new DataflowLinkOptions { PropagateCompletion = true });

        // Paso 4: Postear datos al pipeline
        foreach (var n in new[] { 1, 2, 3, 4, 5 })
        {
            transformBlock.Post(n);
        }

        // Paso 5: Señalar fin de entrada
        transformBlock.Complete();

        // Paso 6: Esperar a que el pipeline termine
        await actionBlock.Completion;

        Console.WriteLine("Procesamiento completo.");
    }
}
```

---

### Explicación paso a paso:

| Paso | Descripción |
|------|-------------|
| 1. `TransformBlock` | Recibe datos, los procesa (aquí multiplica por 2), y los pasa al siguiente bloque. |
| 2. `ActionBlock` | Consume el resultado y lo muestra por consola. |
| 3. `LinkTo` | Conecta ambos bloques para que trabajen en flujo continuo. |
| 4. `Post()` | Envia datos al pipeline. |
| 5. `Complete()` | Señala que no se enviarán más datos. |
| 6. `await Completion` | Espera que todos los datos se procesen antes de cerrar. |

---

Esto sí implementa el **patrón Dataflow completo**: con bloques enlazados, procesamiento asincrónico y desacople entre etapas.


Patrón **Dataflow** en un escenario más realista y completo. El flujo de procesamiento es para una tienda en línea, donde cada pedido pasa por varias etapas:

---

### 🛒 Escenario: Procesamiento de Pedidos

**Etapas:**
1. **Recepción del pedido**
2. **Validación del pedido**
3. **Procesamiento de pago**
4. **Confirmación y notificación**

---

### 💻 Implementación con Dataflow

```csharp
using System;
using System.Threading.Tasks;
using System.Threading.Tasks.Dataflow;

class Program
{
    static async Task Main()
    {
        // Etapa 1: Recepción
        var recepcionBlock = new TransformBlock<string, string>(pedido =>
        {
            Console.WriteLine($"Pedido recibido: {pedido}");
            return pedido;
        });

        // Etapa 2: Validación
        var validacionBlock = new TransformBlock<string, string>(pedido =>
        {
            Console.WriteLine($"Validando pedido: {pedido}");
            if (string.IsNullOrWhiteSpace(pedido)) throw new ArgumentException("Pedido inválido");
            return pedido;
        });

        // Etapa 3: Procesamiento de pago
        var pagoBlock = new TransformBlock<string, string>(pedido =>
        {
            Console.WriteLine($"Procesando pago de: {pedido}");
            Task.Delay(500).Wait(); // Simula espera
            return pedido;
        });

        // Etapa 4: Confirmación
        var confirmacionBlock = new ActionBlock<string>(pedido =>
        {
            Console.WriteLine($"Pedido confirmado y cliente notificado: {pedido}");
        });

        // Encadenar bloques
        recepcionBlock.LinkTo(validacionBlock, new DataflowLinkOptions { PropagateCompletion = true });
        validacionBlock.LinkTo(pagoBlock, new DataflowLinkOptions { PropagateCompletion = true });
        pagoBlock.LinkTo(confirmacionBlock, new DataflowLinkOptions { PropagateCompletion = true });

        // Enviar pedidos
        foreach (var pedido in new[] { "Pedido #1", "Pedido #2", "Pedido #3" })
        {
            recepcionBlock.Post(pedido);
        }

        // Señalar fin del pipeline
        recepcionBlock.Complete();

        // Esperar fin del procesamiento
        await confirmacionBlock.Completion;

        Console.WriteLine("Todos los pedidos han sido procesados.");
    }
}
```

---

### 🔎 ¿Qué estamos simulando aquí?

| Etapa                | Descripción                                                                 |
|----------------------|------------------------------------------------------------------------------|
| Recepción            | Se recibe el pedido.                                                        |
| Validación           | Se verifica que el pedido sea válido.                                       |
| Procesamiento de pago| Simula una demora para representar la autorización de pago.                 |
| Confirmación         | Se notifica al cliente del pedido exitoso.                                  |

---

Este ejemplo simula **un pipeline de procesamiento real**, desacoplado y concurrente.


**Extender el pipeline con manejo de errores y reintentos automáticos**. Esto es muy útil en escenarios reales donde, por ejemplo, un pago puede fallar momentáneamente, o un pedido puede estar mal formado.

----------

###  Requisitos 

1.  **Manejo de errores en etapas críticas** (por ejemplo, validación y pago).
    
2.  **Reintentos automáticos** si un paso falla temporalmente.
    
3.  **Log de errores en consola** para seguimiento.
    

----------

###  Implementación con manejo de errores y reintentos

Aquí usamos `TransformBlock` con lógica de reintento en el procesamiento de pagos:

```csharp
using System;
using System.Threading.Tasks;
using System.Threading.Tasks.Dataflow;

class Program
{
    static async Task Main()
    {
        var recepcionBlock = new TransformBlock<string, string>(pedido =>
        {
            Console.WriteLine($"Pedido recibido: {pedido}");
            return pedido;
        });

        var validacionBlock = new TransformBlock<string, string>(pedido =>
        {
            Console.WriteLine($"Validando pedido: {pedido}");
            if (pedido == "Pedido inválido") throw new ArgumentException("Pedido inválido");
            return pedido;
        });

        var pagoBlock = new TransformBlock<string, string>(async pedido =>
        {
            int intentos = 0;
            while (true)
            {
                try
                {
                    intentos++;
                    Console.WriteLine($"Procesando pago de: {pedido} (Intento {intentos})");
                    if (pedido.Contains("#2") && intentos < 2)
                        throw new Exception("Error temporal en el pago.");
                    await Task.Delay(500);
                    return pedido;
                }
                catch (Exception ex)
                {
                    Console.WriteLine($"Error: {ex.Message}");
                    if (intentos >= 3)
                        throw;
                    await Task.Delay(1000); // Espera antes de reintentar
                }
            }
        });

        var confirmacionBlock = new ActionBlock<string>(pedido =>
        {
            Console.WriteLine($"Pedido confirmado: {pedido}");
        });

        // Enlace entre bloques
        var opciones = new DataflowLinkOptions { PropagateCompletion = true };
        recepcionBlock.LinkTo(validacionBlock, opciones);
        validacionBlock.LinkTo(pagoBlock, opciones, pedido => true); // flujo normal
        validacionBlock.LinkTo(DataflowBlock.NullTarget<string>(), pedido => false); // descartar inválidos
        pagoBlock.LinkTo(confirmacionBlock, opciones);

        // Enviar pedidos
        var pedidos = new[] { "Pedido #1", "Pedido #2", "Pedido inválido", "Pedido #3" };
        foreach (var pedido in pedidos)
            recepcionBlock.Post(pedido);

        recepcionBlock.Complete();
        await confirmacionBlock.Completion;

        Console.WriteLine("Pipeline finalizado.");
    }
}

```

----------

###  Requerimientos logrados 

-   Se simulan **reintentos automáticos** en el pago si ocurre un error transitorio.
    
-   Se **descartan pedidos inválidos** sin detener el resto del flujo.
    
-   Se mantiene un **flujo asincrónico y paralelo**.
    


----------

### Cola de errores
Extender el pipeline incluyendo una **cola de errores** para registrar pedidos que no pudieron completarse tras los reintentos.

-   Una nueva etapa (`registroErroresBlock`) que recibe pedidos fallidos.
    
-   Manejo de errores con `Try...Catch` en el bloque de pago para redirigir fallos definitivos.
    

----------

### Código extendido con cola de errores

```csharp
using System;
using System.Threading.Tasks;
using System.Threading.Tasks.Dataflow;

class Program
{
    static async Task Main()
    {
        var recepcionBlock = new TransformBlock<string, string>(pedido =>
        {
            Console.WriteLine($"Pedido recibido: {pedido}");
            return pedido;
        });

        var validacionBlock = new TransformBlock<string, string>(pedido =>
        {
            Console.WriteLine($"Validando pedido: {pedido}");
            if (pedido == "Pedido inválido") throw new ArgumentException("Pedido inválido");
            return pedido;
        });

        var pagoBlock = new TransformManyBlock<string, string>(async pedido =>
        {
            int intentos = 0;
            while (true)
            {
                try
                {
                    intentos++;
                    Console.WriteLine($"Procesando pago: {pedido} (Intento {intentos})");
                    if (pedido.Contains("#2") && intentos < 2)
                        throw new Exception("Error temporal en pago.");
                    await Task.Delay(500);
                    return new[] { pedido }; // éxito
                }
                catch (Exception ex)
                {
                    Console.WriteLine($"Error: {ex.Message}");
                    if (intentos >= 3)
                        return Array.Empty<string>(); // será redirigido a error
                    await Task.Delay(1000);
                }
            }
        });

        var confirmacionBlock = new ActionBlock<string>(pedido =>
        {
            Console.WriteLine($"Pedido confirmado: {pedido}");
        });

        var registroErroresBlock = new ActionBlock<string>(pedido =>
        {
            Console.WriteLine($"Pedido fallido: {pedido}");
        });

        var opciones = new DataflowLinkOptions { PropagateCompletion = true };

        // Flujo principal
        recepcionBlock.LinkTo(validacionBlock, opciones);
        validacionBlock.LinkTo(pagoBlock, opciones);
        pagoBlock.LinkTo(confirmacionBlock, opciones, pedido => !string.IsNullOrWhiteSpace(pedido));
        pagoBlock.LinkTo(registroErroresBlock, opciones, pedido => string.IsNullOrWhiteSpace(pedido));

        // Enviar pedidos
        var pedidos = new[] { "Pedido #1", "Pedido #2", "Pedido inválido", "Pedido #3" };
        foreach (var pedido in pedidos)
            recepcionBlock.Post(pedido);

        recepcionBlock.Complete();
        await Task.WhenAll(confirmacionBlock.Completion, registroErroresBlock.Completion);

        Console.WriteLine("Pipeline finalizado con manejo de errores.");
    }
}

```

----------

###  Ventajas de la implementación 

-   Se evitan bloqueos al separar los errores en otro flujo.
    
-   Los pedidos problemáticos se registran sin detener el pipeline.
    
-   El flujo completo es resiliente ante fallas puntuales.
    



----------

## 🔹 **🚀 Incrementando el Paralelismo Utilizando el Patrón Pipeline y Dataflow**

Al aplicar los patrones Pipeline y Dataflow, podemos incrementar el paralelismo al dividir las tareas en unidades más pequeñas y ejecutarlas de manera concurrente. Al incrementar el paralelismo, podemos mejorar el rendimiento y reducir el tiempo de procesamiento.

En el caso del patrón **Pipeline**, cada etapa puede ser ejecutada en paralelo, lo que nos permite aumentar la eficiencia del procesamiento de datos. En el caso del patrón **Dataflow**, podemos realizar tareas independientes y concurrentes en diferentes nodos.

----------

## 🔹 **👥 Uso de Estructuras de Datos Concurrentes**

Cuando trabajamos con programación concurrente, es esencial usar **estructuras de datos concurrentes** que permitan el acceso seguro desde múltiples hilos. Ejemplos comunes de estas estructuras son las **colas concurrentes** (como `ConcurrentQueue`) y los **diccionarios concurrentes** (`ConcurrentDictionary`).

Estas estructuras nos permiten manejar la sincronización de manera eficiente, sin tener que preocuparnos por los bloqueos manuales.

**Ejemplo de uso de `ConcurrentQueue`:**

```csharp
using System;
using System.Collections.Concurrent;
using System.Threading.Tasks;

class Program
{
    static void Main()
    {
        var queue = new ConcurrentQueue<int>();
        
        // Insertar elementos en la cola concurrente
        for (int i = 0; i < 10; i++)
        {
            queue.Enqueue(i);
        }

        // Procesar elementos en paralelo
        var tasks = new Task[10];
        for (int i = 0; i < 10; i++)
        {
            tasks[i] = Task.Run(() => ProcessQueue(queue));
        }

        Task.WhenAll(tasks).Wait();
        Console.WriteLine("Procesamiento completado.");
    }

    static void ProcessQueue(ConcurrentQueue<int> queue)
    {
        if (queue.TryDequeue(out var item))
        {
            Console.WriteLine($"Procesando {item}...");
        }
    }
}

```

En este ejemplo, estamos utilizando una `ConcurrentQueue` para almacenar y procesar elementos de forma segura desde múltiples hilos.

----------

## 🔹 **📦 Patrón Productor-Consumidor**

El **Patrón Productor-Consumidor** es un patrón clásico en la programación concurrente donde hay un productor que genera datos y un consumidor que los procesa. Entre el productor y el consumidor hay una **cola** (o buffer), que almacena los elementos hasta que el consumidor pueda procesarlos.

Este patrón es útil cuando hay una desaceleración en el procesamiento y el productor sigue generando datos a un ritmo más rápido que el consumidor.

**Ejemplo en C#:**

```csharp
using System;
using System.Collections.Concurrent;
using System.Threading;
using System.Threading.Tasks;

class Program
{
    static async Task Main()
    {
        var queue = new BlockingCollection<int>();
        
        // Crear y ejecutar el productor
        var producer = Task.Run(() => Produce(queue));
        
        // Crear y ejecutar el consumidor
        var consumer = Task.Run(() => Consume(queue));

        await Task.WhenAll(producer, consumer);
    }

    static void Produce(BlockingCollection<int> queue)
    {
        for (int i = 0; i < 10; i++)
        {
            queue.Add(i);
            Console.WriteLine($"Productor ha agregado {i}.");
            Thread.Sleep(500);
        }
        queue.CompleteAdding();
    }

    static void Consume(BlockingCollection<int> queue)
    {
        foreach (var item in queue.GetConsumingEnumerable())
        {
            Console.WriteLine($"Consumidor está procesando {item}.");
            Thread.Sleep(1000);
        }
    }
}

```

En este ejemplo, el **Productor** agrega elementos a la **BlockingCollection** y el **Consumidor** los procesa, uno a uno. La **BlockingCollection** garantiza que los elementos sean manejados de manera segura.

----------

## 🔹 **🧩 Patrón "Map-Reduce"**

El **Patrón Map-Reduce** es utilizado para dividir tareas grandes en subtareas pequeñas que pueden ser procesadas en paralelo. Una vez procesadas las subtareas, los resultados se combinan (reduce) para obtener el resultado final. Es ideal para procesamiento de grandes volúmenes de datos, como análisis de datos y procesamiento de texto.

**Ejemplo en C#:**

```csharp
using System;
using System.Linq;
using System.Threading.Tasks;

class Program
{
    static async Task Main()
    {
        var data = new int[] { 1, 2, 3, 4, 5 };

        // Paso 1: Mapeo (cada número se multiplica por 2)
        var mappedData = data.AsParallel().Select(x => x * 2);

        // Paso 2: Reducción (sumar todos los resultados)
        var result = mappedData.Sum();

        Console.WriteLine($"Resultado final de Map-Reduce: {result}");
    }
}

```

En este ejemplo, aplicamos el patrón Map-Reduce en dos pasos: **Map** (multiplicamos los elementos por 2) y **Reduce** (sumamos los resultados).

----------

## **🗺️ Mapa Conceptual de la Unidad 4: Diseño de Patrones para Programación Concurrente**

```
                     +---------------------------------------+
                     |   Diseño de Patrones para Programación|
                     |            Concurrente               |
                     +---------------------------------------+
                                   |
             +---------------------+---------------------+
             |                                           |
   +-----------------+                          +----------------+
   |  Patrón Pipeline|                          |   Patrón Dataflow|
   |       ⏳         |                          |      🔄          |
   +-----------------+                          +----------------+
             |                                           |
   +------------------+                          +----------------+
   | Incrementando el |                          | Uso de Estructuras|
   | Paralelismo      |                          | Concurrentes      |
   |   🚀             |                          |    📚            |
   +------------------+                          +----------------+
                                   |
                   +-------------------------------+
                   | Patrón Productor-Consumidor    |
                   |            👥                   |
                   +-------------------------------+
                                   |
                  +----------------------------------+
                  |       Patrón Map-Reduce         |
                  |              🧩                 |
                  +----------------------------------+

```

----------

### **🗺️ Mapa Conceptual Detallado**

**Diseño de Patrones para Programación Concurrente**  
Este es el concepto principal de la unidad, que cubre la utilización de patrones específicos para gestionar la programación concurrente de manera más eficiente y organizada.

----------

#### **1. Patrón "Pipeline" ⏳**

-   **Objetivo:** Este patrón ayuda a organizar las tareas de procesamiento en etapas que pueden ejecutarse en paralelo.
    
-   **Conexión con la unidad:** Ayuda a mejorar la eficiencia del procesamiento de datos cuando el flujo de trabajo puede dividirse en pasos independientes.
    

----------

#### **2. Patrón "Dataflow" 🔄**

-   **Objetivo:** Similar al patrón "Pipeline", pero más flexible. Aquí, los datos fluyen a través de múltiples nodos que realizan tareas independientes en paralelo.
    
-   **Conexión con la unidad:** Facilita el diseño de sistemas donde varias tareas concurrentes consumen y producen datos sin depender unas de otras.
    

----------

#### **3. Incrementando el Paralelismo 🚀**

-   **Objetivo:** El paralelismo se incrementa utilizando los patrones mencionados ("Pipeline" y "Dataflow"), ya que al dividir las tareas en pasos o nodos más pequeños, podemos ejecutar más operaciones de manera concurrente.
    
-   **Conexión con la unidad:** Cuando incrementamos el paralelismo, aprovechamos mejor los recursos del sistema y reducimos el tiempo de ejecución al realizar tareas simultáneamente.
    

----------

#### **4. Uso de Estructuras Concurrentes 📚**

-   **Objetivo:** Las estructuras de datos concurrentes como `ConcurrentQueue`, `BlockingCollection` y `ConcurrentDictionary` permiten un acceso seguro desde múltiples hilos sin necesidad de bloqueos manuales.
    
-   **Conexión con la unidad:** Permite manejar los datos de manera eficiente cuando estamos trabajando con múltiples hilos y tareas paralelas, ayudando a evitar errores de concurrencia.
    

----------

#### **5. Patrón Productor-Consumidor 👥**

-   **Objetivo:** Separa las responsabilidades de generar datos (productor) y procesarlos (consumidor). Utiliza una cola para almacenar datos que el consumidor procesará.
    
-   **Conexión con la unidad:** Este patrón permite gestionar el flujo de datos de manera concurrente, manteniendo el sistema eficiente cuando la producción y el consumo de datos ocurren a diferentes ritmos.
    

----------

#### **6. Patrón "Map-Reduce" 🧩**

-   **Objetivo:** Divide una tarea en subtareas pequeñas que se ejecutan en paralelo (Map) y luego combina los resultados (Reduce) para obtener el resultado final.
    
-   **Conexión con la unidad:** Es muy útil cuando necesitamos procesar grandes volúmenes de datos y queremos distribuir ese trabajo de manera paralela, aprovechando al máximo los recursos del sistema.
    

----------

### **Conexión General entre los Conceptos:**

1.  **Patrones de Diseño Concurrentes**  
    Los patrones "Pipeline", "Dataflow", "Productor-Consumidor" y "Map-Reduce" están relacionados entre sí porque todos abordan cómo organizar y manejar tareas concurrentes para aprovechar mejor el paralelismo en la programación.
    
2.  **Incremento del Paralelismo y Estructuras Concurrentes**  
    Incrementar el paralelismo con los patrones mencionados también va de la mano con el uso de estructuras de datos concurrentes, como las colas concurrentes, que permiten un acceso eficiente a los datos de manera segura entre los hilos.
    
3.  **Reducción de Complejidad**  
    Usar estos patrones ayuda a reducir la complejidad del código y hace que el procesamiento concurrente sea más fácil de gestionar y escalar, especialmente cuando se trata de manejar grandes volúmenes de datos o realizar tareas simultáneas.
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTM2MTM5MDQ5MF19
-->